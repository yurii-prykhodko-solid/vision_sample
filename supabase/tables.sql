create table videos (
    id bigint generated by default as identity not null,
    url text not null unique,
    storage_link text, -- gets set once the video is downloaded
    metadata jsonb,
    primary key (id)
);

create table clips (
    id bigint generated by default as identity not null,
    video_id bigint not null references videos (id) on delete cascade,
    start interval,
    end interval,
    storage_link text not null,
    metadata jsonb
);

-- one to many relationship, as a video may have several transcripts.
-- One case could be that the transcription algo was improved, 
-- and we may want to go back and regenerate
-- transcripts for old videos.
create table video_transcripts (
    id bigint generated by default as identity not null,
    contents jsonb not null,
    video_id bigint not null references videos (id) on delete cascade,
    created_at timestamp with time zone default current_timestamp not null
);

create table clip_transcripts (
    id bigint generated by default as identity not null,
    contents jsonb not null,
    clip_id integer not null references clips (id) on delete cascade
    created_at timestamp with time zone default current_timestamp not null
);

-- the video_ and clip_ split is redundant, but it makes operations on the tables a bit simpler.
-- We can merge these together:
-- 
-- create table transcripts (
--     id bigint generated by default as identity not null,
--     contents jsonb not null,
--     video_id bigint references videos (id) on delete cascade,
--     clip_id bigint references clips (id) on delete cascade,
--     check (
--         (video_id is not null and clip_id is null) or
--         (video_id is null and clip_id is not null)
--     )
-- );
-- 
-- but then we'll constantly need to check which transcript we're operating on -- video or clip,
-- like: 
-- select * from transcripts where video_id is not null;
-- instead of just:
-- select * from video_transcripts;
-- 
-- besides, if we predominantly want to operate on one or the other,
-- split tables should give us better performance.

-- since the content type 
create table video_content_type (
    id bigint generated by default as identity not null,
    type text not null,
    video_id bigint not null references videos (id) on delete cascade,
    created_at timestamp with time zone default current_timestamp not null
);


create table video_tags (
    id bigint generated by default as identity not null,
    video_id bigint not null references videos (id) on delete cascade,
    tag text not null
);

create table clip_tags (
    id bigint generated by default as identity not null,
    clip_id integer not null references clips (id) on delete cascade,
    tag text not null
);


-- video processing pipeline may fail at any point, so we need a way to retry.
create domain queue_status as text check (value in ('pending', 'in_progress', 'completed', 'failed'));

-- ideally, we want to break out each of these steps into a separate queue,
-- and preserve the result of each step.
-- that way, we will be able to preserve progress should anything go down,
-- and retry from a checkpoint.
create domain video_processing_step as text check (value in (
    'queued', 
    'download',
    'transcription',
    'content_type_identification',
    'insightful_clip_lookup',
    'clip_generation'
));

-- this table serves both as a pending task queue and a DLQ.
-- each time we traverse a step, we preserve the results of that step in one of the tables above.
-- We can try to preserve everything, or we can be selective and store only the results of expensive operations.
create table video_processing_queue (
    id bigint generated by default as identity not null,
    video_id bigint not null references videos (id) on delete cascade,
    priority integer not null default 0,
    queue_status queue_status not null default 'pending',
    pipeline_step video_processing_step not null default 'queued',
    retry int not null default 0,
    failure_cause text,
    failure_details jsonb,
    created_at timestamp with time zone not null default current_timestamp,
    updated_at timestamp with time zone not null default current_timestamp
);
